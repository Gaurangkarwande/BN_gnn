{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.readwrite import BIFReader\n",
    "from pathlib import Path\n",
    "from src.utils import adj_df_from_BIF, get_train_test_splits, encode_data, get_terminal_connection_nodes\n",
    "from src.data import BNDataset\n",
    "from src.models.BNNet import BNNet\n",
    "from src.train import train\n",
    "from src.constants import HEPAR_TARGET\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import dense_to_sparse, to_torch_coo_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 64,\n",
       " 'gnn_hidden_dim': 64,\n",
       " 'gnn_out_dim': 3,\n",
       " 'fc1_out_dim': 16,\n",
       " 'batch_size_train': 64,\n",
       " 'batch_size_val': 64,\n",
       " 'batch_size_test': 64,\n",
       " 'num_epochs': 50,\n",
       " 'patience': 10,\n",
       " 'min_delta': 1e-05,\n",
       " 'lr': 0.01}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_bif = Path(\"/home/gaurang/bayesian_network/data/hepar/hepar2.bif\")\n",
    "fpath_data = Path(\"/home/gaurang/bayesian_network/data/hepar/HEPARTWO10k.csv\")\n",
    "fpath_config = Path(\"/home/gaurang/bayesian_network/code/src/config.yaml\")\n",
    "\n",
    "with open(fpath_config, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BIFReader(fpath_bif)\n",
    "adj_df = adj_df_from_BIF(bn)\n",
    "adj_df_perturb = adj_df_from_BIF(bn, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PBC', 'joints'], [13, 33])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_terminal_connection_nodes(adj_df, target=HEPAR_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(fpath_data, dtype=str)\n",
    "df_data, encoder = encode_data(df_data, bn)\n",
    "df_train, df_valid, df_test = get_train_test_splits(df_data, 123, False)\n",
    "reader = BIFReader(fpath_bif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "perturbation_factor = 0.5\n",
    "adj_df = adj_df_from_BIF(reader, perturbation_factor)\n",
    "\n",
    "train_set = BNDataset(df_data=df_train, target_node=HEPAR_TARGET, bn=reader, adj_df=adj_df, perturbation_factor=perturbation_factor)\n",
    "val_set = BNDataset(df_data=df_valid, target_node=HEPAR_TARGET, bn=reader, adj_df=adj_df, perturbation_factor=perturbation_factor)\n",
    "test_set = BNDataset(df_data=df_test, target_node=HEPAR_TARGET, bn=reader, adj_df=adj_df, perturbation_factor=perturbation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_set, batch_size=config[\"batch_size_train\"])\n",
    "dataloader_valid = DataLoader(val_set, batch_size=config[\"batch_size_val\"])\n",
    "dataloader_test = DataLoader(test_set, batch_size=config[\"batch_size_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataloader_train)\n",
    "batch = next(it)\n",
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BNNet(\n",
    "        config=config,\n",
    "        num_nodes= len(train_set.input_nodes),\n",
    "        node_states=train_set.input_states,\n",
    "        edge_index=train_set.edge_index,\n",
    "        terminal_node_ids=train_set.terminal_node_ids,\n",
    "        target_node_states=train_set.target_states\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BNNet(\n",
       "  (node_embedding_layers): ModuleList(\n",
       "    (0): Embedding(2, 64)\n",
       "    (1): Embedding(2, 64)\n",
       "    (2): Embedding(2, 64)\n",
       "    (3): Embedding(2, 64)\n",
       "    (4): Embedding(2, 64)\n",
       "    (5): Embedding(2, 64)\n",
       "    (6): Embedding(2, 64)\n",
       "    (7): Embedding(2, 64)\n",
       "    (8): Embedding(2, 64)\n",
       "    (9): Embedding(2, 64)\n",
       "    (10): Embedding(3, 64)\n",
       "    (11): Embedding(2, 64)\n",
       "    (12): Embedding(4, 64)\n",
       "    (13): Embedding(2, 64)\n",
       "    (14): Embedding(2, 64)\n",
       "    (15): Embedding(2, 64)\n",
       "    (16): Embedding(2, 64)\n",
       "    (17): Embedding(2, 64)\n",
       "    (18): Embedding(3, 64)\n",
       "    (19): Embedding(2, 64)\n",
       "    (20): Embedding(3, 64)\n",
       "    (21): Embedding(2, 64)\n",
       "    (22): Embedding(2, 64)\n",
       "    (23): Embedding(4, 64)\n",
       "    (24): Embedding(2, 64)\n",
       "    (25): Embedding(2, 64)\n",
       "    (26): Embedding(2, 64)\n",
       "    (27): Embedding(2, 64)\n",
       "    (28): Embedding(2, 64)\n",
       "    (29): Embedding(3, 64)\n",
       "    (30): Embedding(2, 64)\n",
       "    (31): Embedding(2, 64)\n",
       "    (32): Embedding(2, 64)\n",
       "    (33): Embedding(2, 64)\n",
       "    (34): Embedding(2, 64)\n",
       "    (35): Embedding(2, 64)\n",
       "    (36): Embedding(4, 64)\n",
       "    (37): Embedding(3, 64)\n",
       "    (38): Embedding(2, 64)\n",
       "    (39): Embedding(2, 64)\n",
       "    (40): Embedding(2, 64)\n",
       "    (41): Embedding(2, 64)\n",
       "    (42): Embedding(3, 64)\n",
       "    (43): Embedding(2, 64)\n",
       "    (44): Embedding(2, 64)\n",
       "    (45): Embedding(2, 64)\n",
       "    (46): Embedding(2, 64)\n",
       "    (47): Embedding(3, 64)\n",
       "    (48): Embedding(4, 64)\n",
       "    (49): Embedding(4, 64)\n",
       "    (50): Embedding(3, 64)\n",
       "    (51): Embedding(4, 64)\n",
       "    (52): Embedding(3, 64)\n",
       "    (53): Embedding(2, 64)\n",
       "    (54): Embedding(2, 64)\n",
       "    (55): Embedding(2, 64)\n",
       "    (56): Embedding(2, 64)\n",
       "    (57): Embedding(2, 64)\n",
       "    (58): Embedding(2, 64)\n",
       "    (59): Embedding(2, 64)\n",
       "    (60): Embedding(2, 64)\n",
       "    (61): Embedding(3, 64)\n",
       "    (62): Embedding(2, 64)\n",
       "    (63): Embedding(2, 64)\n",
       "    (64): Embedding(2, 64)\n",
       "    (65): Embedding(2, 64)\n",
       "    (66): Embedding(2, 64)\n",
       "    (67): Embedding(2, 64)\n",
       "    (68): Embedding(2, 64)\n",
       "  )\n",
       "  (gnn): GNN(\n",
       "    (layer1): GCNConv(64, 64)\n",
       "    (layer2): GCNConv(64, 3)\n",
       "  )\n",
       "  (MLP): Sequential(\n",
       "    (0): Linear(in_features=102, out_features=16, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=16, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(4, 10, 3)\n",
    "torch.mean(t, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5105e-02,  2.7054e-01],\n",
       "        [ 8.8343e-03,  2.6897e-01],\n",
       "        [-6.1352e-03,  2.8246e-01],\n",
       "        [-2.1062e-02,  2.7114e-01],\n",
       "        [-1.8376e-02,  2.7396e-01],\n",
       "        [-1.1731e-02,  2.7468e-01],\n",
       "        [-2.3099e-02,  2.7158e-01],\n",
       "        [ 2.4742e-02,  2.5692e-01],\n",
       "        [-1.0178e-03,  2.7386e-01],\n",
       "        [ 2.1685e-02,  2.6322e-01],\n",
       "        [ 1.7473e-02,  2.4702e-01],\n",
       "        [-6.9723e-03,  2.6868e-01],\n",
       "        [-4.5472e-03,  2.7752e-01],\n",
       "        [ 8.0732e-03,  2.6227e-01],\n",
       "        [ 2.3318e-02,  2.4276e-01],\n",
       "        [-2.0328e-02,  2.7826e-01],\n",
       "        [ 5.4301e-03,  2.5697e-01],\n",
       "        [ 1.6076e-02,  2.7205e-01],\n",
       "        [ 2.0962e-02,  2.3470e-01],\n",
       "        [-1.4158e-02,  2.7347e-01],\n",
       "        [ 2.3200e-02,  2.6288e-01],\n",
       "        [-3.6817e-04,  2.7776e-01],\n",
       "        [ 1.7817e-02,  2.7586e-01],\n",
       "        [ 1.1436e-02,  2.5865e-01],\n",
       "        [ 1.8086e-02,  2.6617e-01],\n",
       "        [ 1.2256e-02,  2.7670e-01],\n",
       "        [ 2.4006e-02,  2.7639e-01],\n",
       "        [-5.4381e-04,  2.6660e-01],\n",
       "        [ 2.3130e-02,  2.7171e-01],\n",
       "        [ 2.3794e-02,  2.7015e-01],\n",
       "        [ 2.1043e-02,  2.7783e-01],\n",
       "        [-2.9366e-03,  2.7788e-01],\n",
       "        [-3.2391e-02,  2.7748e-01],\n",
       "        [ 1.3015e-02,  2.6004e-01],\n",
       "        [ 1.6111e-02,  2.7316e-01],\n",
       "        [ 2.6837e-02,  2.6956e-01],\n",
       "        [ 1.5412e-02,  2.4367e-01],\n",
       "        [ 1.5778e-02,  2.6214e-01],\n",
       "        [ 1.3310e-05,  2.7488e-01],\n",
       "        [ 1.0342e-02,  2.7673e-01],\n",
       "        [-3.9412e-03,  2.7531e-01],\n",
       "        [-2.1189e-02,  2.7895e-01],\n",
       "        [ 1.0479e-02,  2.7228e-01],\n",
       "        [ 1.4906e-02,  2.7057e-01],\n",
       "        [ 1.5785e-03,  2.6902e-01],\n",
       "        [ 1.0826e-02,  2.6548e-01],\n",
       "        [ 7.9722e-04,  2.7491e-01],\n",
       "        [ 1.9800e-02,  2.6938e-01],\n",
       "        [-1.0528e-02,  2.6930e-01],\n",
       "        [ 9.3134e-03,  2.5808e-01],\n",
       "        [ 1.1787e-02,  2.5794e-01],\n",
       "        [ 7.1246e-03,  2.6360e-01],\n",
       "        [ 1.4903e-02,  2.6591e-01],\n",
       "        [ 6.0368e-03,  2.5803e-01],\n",
       "        [ 1.3941e-02,  2.7003e-01],\n",
       "        [ 1.5266e-02,  2.5007e-01],\n",
       "        [ 1.3169e-02,  2.6479e-01],\n",
       "        [ 2.3356e-02,  2.7762e-01],\n",
       "        [-1.9540e-02,  2.7237e-01],\n",
       "        [ 2.0038e-02,  2.6456e-01],\n",
       "        [ 2.1948e-02,  2.6997e-01],\n",
       "        [ 1.3514e-02,  2.6190e-01],\n",
       "        [ 1.9793e-02,  2.6231e-01],\n",
       "        [ 2.3271e-03,  2.6053e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings_list = [len(state) for state in dataset.input_states]\n",
    "node_embedding_layers = [\n",
    "    nn.Embedding(num_emdeddings, 7)\n",
    "    for num_emdeddings in num_embeddings_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_input = []\n",
    "\n",
    "for i, node_embedding_layer in enumerate(node_embedding_layers):\n",
    "    gnn_input.append(node_embedding_layer(X[:, i]))\n",
    "\n",
    "len(gnn_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_input = torch.stack(gnn_input, dim=1)\n",
    "gnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GCNConv(7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = gnn(gnn_input, edge_index)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 360])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(4, -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf = bernoulli(0.0)\n",
    "pmf.rvs(size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device == torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "fpath_inference = Path(\"/home/gaurang/bayesian_network/experiments/alarm/20230213_163627_training_record/inference.csv\")\n",
    "df_inference = pd.read_csv(fpath_inference)\n",
    "\n",
    "y = df_inference['HRSAT']\n",
    "pred = df_inference['predicted_values']\n",
    "\n",
    "accuracy_score(y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e51103ac6c53fe55de20f4620cfe6b8fd548af295bbf13940f7844378471672"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
