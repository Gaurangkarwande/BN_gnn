{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.readwrite import BIFReader\n",
    "from pathlib import Path\n",
    "from src.utils import adj_df_from_BIF, get_train_test_splits, encode_data, get_terminal_connection_nodes\n",
    "from src.data import BNDataset, reconstruct_adj_mats\n",
    "from src.models.BNNet import BNNet\n",
    "from src.train import train\n",
    "from src.constants import HEPAR_TARGET\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "\n",
    "from torch_geometric.nn import GCNConv, FAConv, GATv2Conv\n",
    "from torch_geometric.utils import dense_to_sparse, to_torch_coo_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_dim': 16,\n",
       " 'gnn_hidden_dim': 64,\n",
       " 'gnn_out_dim': 16,\n",
       " 'fc1_out_dim': 16,\n",
       " 'gat_heads': 4,\n",
       " 'batch_size_train': 64,\n",
       " 'batch_size_val': 64,\n",
       " 'batch_size_test': 64,\n",
       " 'num_epochs': 50,\n",
       " 'patience': 10,\n",
       " 'min_delta': 1e-05,\n",
       " 'lr': 0.01}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_bif = Path(\"/home/gaurang/bayesian_network/data/hepar/hepar2.bif\")\n",
    "fpath_data = Path(\"/home/gaurang/bayesian_network/data/hepar/HEPARTWO10k.csv\")\n",
    "fpath_config = Path(\"/home/gaurang/bayesian_network/code/src/config.yaml\")\n",
    "\n",
    "with open(fpath_config, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(fpath_data, dtype=str)\n",
    "bn = BIFReader(fpath_bif)\n",
    "df_data, encoder = encode_data(df_data, bn)\n",
    "df_train, df_valid, df_test = get_train_test_splits(df_data, 123, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "perturbation_factor = 0.0\n",
    "adj_df = adj_df_from_BIF(bn, HEPAR_TARGET, perturbation_factor)\n",
    "\n",
    "train_set = BNDataset(df_data=df_train, target_node=HEPAR_TARGET, bn=bn, adj_df=adj_df, perturbation_factor=perturbation_factor)\n",
    "val_set = BNDataset(df_data=df_valid, target_node=HEPAR_TARGET, bn=bn, adj_df=adj_df, perturbation_factor=perturbation_factor)\n",
    "test_set = BNDataset(df_data=df_test, target_node=HEPAR_TARGET, bn=bn, adj_df=adj_df, perturbation_factor=perturbation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcoholism     0.0\n",
       "vh_amn         0.0\n",
       "hepatotoxic    0.0\n",
       "THepatitis     0.0\n",
       "hospital       0.0\n",
       "              ... \n",
       "hcv_anti       0.0\n",
       "palms          0.0\n",
       "hbeag          0.0\n",
       "carcinoma      0.0\n",
       "pain           0.0\n",
       "Name: pain, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_df['pain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PBC', 'joints'], [13, 33])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_terminal_connection_nodes(adj_df, target=HEPAR_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(train_set, batch_size=config[\"batch_size_train\"])\n",
    "dataloader_valid = DataLoader(val_set, batch_size=config[\"batch_size_val\"])\n",
    "dataloader_test = DataLoader(test_set, batch_size=config[\"batch_size_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataloader_train)\n",
    "batch = next(it)\n",
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BNNet(\n",
    "        config=config,\n",
    "        num_nodes= len(train_set.input_nodes),\n",
    "        node_states=train_set.input_states,\n",
    "        edge_index=train_set.edge_index,\n",
    "        terminal_node_ids=train_set.terminal_node_ids,\n",
    "        target_node_states=train_set.target_states,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.input_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.inference = True\n",
    "    model.gnn.inference = True\n",
    "    model(X)\n",
    "    model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 121])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gnn.edge_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats = reconstruct_adj_mats(input_edge_weights=model.gnn.edge_weights, \n",
    "                              terminal_edge_weights=model.terminal_edge_weights,\n",
    "                              input_edge_index=train_set.edge_index,\n",
    "                              terminal_node_ids=model.terminal_node_ids,\n",
    "                              node_list=adj_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246825"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mats.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat = (torch.mean(adj_mats, dim=0) > 0.4).float().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 70])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(adj_mats, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 70, 70])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mat = adj_mats[0].unsqueeze(0)\n",
    "adj_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 70, 70])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mat.repeat(128, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [2, 121].  Tensor sizes: [121, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gaurang/bayesian_network/code/torch_geometric_data_notebook.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bplanlab/home/gaurang/bayesian_network/code/torch_geometric_data_notebook.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_dense_adj\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bplanlab/home/gaurang/bayesian_network/code/torch_geometric_data_notebook.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dense_adj \u001b[39m=\u001b[39m to_dense_adj(edge_index\u001b[39m=\u001b[39;49mtrain_set\u001b[39m.\u001b[39;49medge_index, edge_attr\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgnn\u001b[39m.\u001b[39;49medge_weights[\u001b[39m0\u001b[39;49m:\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.10/site-packages/torch_geometric/utils/to_dense_adj.py:93\u001b[0m, in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes)\u001b[0m\n\u001b[1;32m     91\u001b[0m adj \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mview([flattened_size] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(adj\u001b[39m.\u001b[39msize())[\u001b[39m3\u001b[39m:])\n\u001b[1;32m     92\u001b[0m idx \u001b[39m=\u001b[39m idx0 \u001b[39m*\u001b[39m max_num_nodes \u001b[39m*\u001b[39m max_num_nodes \u001b[39m+\u001b[39m idx1 \u001b[39m*\u001b[39m max_num_nodes \u001b[39m+\u001b[39m idx2\n\u001b[0;32m---> 93\u001b[0m scatter(edge_attr, idx, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49madj, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39madd\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     94\u001b[0m adj \u001b[39m=\u001b[39m adj\u001b[39m.\u001b[39mview(size)\n\u001b[1;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m adj\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.10/site-packages/torch_scatter/scatter.py:152\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m|\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m    torch.Size([10, 3, 64])\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_sum(src, index, dim, out, dim_size)\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmul\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_mul(src, index, dim, out, dim_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.10/site-packages/torch_scatter/scatter.py:11\u001b[0m, in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_sum\u001b[39m(src: torch\u001b[39m.\u001b[39mTensor, index: torch\u001b[39m.\u001b[39mTensor, dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 out: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                 dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 11\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m         size \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(src\u001b[39m.\u001b[39msize())\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.10/site-packages/torch_scatter/utils.py:12\u001b[0m, in \u001b[0;36mbroadcast\u001b[0;34m(src, other, dim)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(src\u001b[39m.\u001b[39mdim(), other\u001b[39m.\u001b[39mdim()):\n\u001b[1;32m     11\u001b[0m     src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49mexpand(other\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m     13\u001b[0m \u001b[39mreturn\u001b[39;00m src\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (121) at non-singleton dimension 0.  Target sizes: [2, 121].  Tensor sizes: [121, 1]"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "dense_adj = to_dense_adj(edge_index=train_set.edge_index, edge_attr=model.gnn.edge_weights[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 69, 69])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(117)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(edge_weights > 0.1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor([[1,2,3], [3,4,3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(train_set.edge_index, model.gnn.batch_edge_index[:, 121:(121+121)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edge_index(edge_index):\n",
    "    num_nodes = 69*2\n",
    "    return edge_index - num_nodes\n",
    "\n",
    "torch.equal(train_set.edge_index, get_edge_index(model.gnn.batch_edge_index[:, 242:363]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4880, -0.3466], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.MLP[1].weight.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = MultiheadAttention(32, 4, dropout=True, batch_first=True)\n",
    "\n",
    "x = torch.rand(10, 3, 32)\n",
    "\n",
    "out, weights = attn(x, x, x)\n",
    "\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(weights, out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights_diag = torch.diagonal(weights, dim1=-2, dim2=-1)\n",
    "attn_weights_scalar = attn_weights_diag.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((attn_weights_diag, attn_weights_diag)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights_diag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 69, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_input = []\n",
    "\n",
    "for i, node_embedding_layer in enumerate(model.node_embedding_layers):\n",
    "    gnn_input.append(node_embedding_layer(X[:, i]))\n",
    "\n",
    "x = torch.stack(gnn_input, dim=1)\n",
    "x = x[:4, :, :]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 121])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "edge_index = model.gnn.edge_index\n",
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_edge_index = edge_index\n",
    "for i in range(1, x.shape[0]):\n",
    "    batch_edge_index = torch.cat((batch_edge_index, edge_index + i*model.num_nodes), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 69, 64])\n",
      "torch.Size([2, 484])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(batch_edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = FAConv(channels=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 69, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn(x.view(x.shape[0]*x.shape[1], -1), x.view(x.shape[0]*x.shape[1], -1), batch_edge_index).view(-1, model.num_nodes, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings_list = [len(state) for state in dataset.input_states]\n",
    "node_embedding_layers = [\n",
    "    nn.Embedding(num_emdeddings, 7)\n",
    "    for num_emdeddings in num_embeddings_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_input = []\n",
    "\n",
    "for i, node_embedding_layer in enumerate(node_embedding_layers):\n",
    "    gnn_input.append(node_embedding_layer(X[:, i]))\n",
    "\n",
    "len(gnn_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36, 7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_input = torch.stack(gnn_input, dim=1)\n",
    "gnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GCNConv(7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 36, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = gnn(gnn_input, edge_index)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 360])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(4, -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmf = bernoulli(0.0)\n",
    "pmf.rvs(size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device == torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "fpath_inference = Path(\"/home/gaurang/bayesian_network/experiments/alarm/20230213_163627_training_record/inference.csv\")\n",
    "df_inference = pd.read_csv(fpath_inference)\n",
    "\n",
    "y = df_inference['HRSAT']\n",
    "pred = df_inference['predicted_values']\n",
    "\n",
    "accuracy_score(y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e51103ac6c53fe55de20f4620cfe6b8fd548af295bbf13940f7844378471672"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
